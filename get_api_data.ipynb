{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "namer=pd.read_csv('data/StationCode_mapper.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subwayLine</th>\n",
       "      <th>stationName</th>\n",
       "      <th>stationCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2호선</td>\n",
       "      <td>신림역</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subwayLine stationName stationCode\n",
       "97        2호선         신림역         230"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets => [공덕역,선릉역,신림역]\n",
    "namer[namer['stationName']=='신림역']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from private._private_ import app_key\n",
    "\n",
    "results = list()\n",
    "hours = [7,8,9,17,18,19,20]\n",
    "dows = ['MON', 'TUE', 'WED', 'THU', 'FRI']\n",
    "sc = 230\n",
    "\n",
    "for hour in hours:\n",
    "    for dow in dows:\n",
    "        url = f\"https://apis.openapi.sk.com/puzzle/congestion-train/stat/stations/{sc}?dow={dow}&hh={str(hour).zfill(2)}\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"appkey\": app_key()\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        res_dict=eval(response.text)\n",
    "        using_data = list()\n",
    "        for trains in res_dict['contents']['stat']:\n",
    "            count = 0\n",
    "            for train in trains['data']:\n",
    "                if train['congestionTrain'] == 0:\n",
    "                    count += 1\n",
    "            if count == 0:\n",
    "                using_data.append(trains)\n",
    "                \n",
    "        df_main = pd.DataFrame(using_data)\n",
    "        df_main['subwayLine'] =res_dict['contents']['subwayLine']\n",
    "        df_main['stationName'] =res_dict['contents']['stationName']\n",
    "        results.append(df_main)\n",
    "df_1=pd.concat(results)\n",
    "\n",
    "\n",
    "results = list()\n",
    "for hour in hours:\n",
    "    for dow in dows:\n",
    "        url = f\"https://apis.openapi.sk.com/puzzle/congestion-car/stat/stations/{sc}?dow={dow}&hh={str(hour).zfill(2)}\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"appkey\": app_key()\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        res_dict=eval(response.text)\n",
    "        using_data = list()\n",
    "        for trains in res_dict['contents']['stat']:\n",
    "            count = 0\n",
    "            for train in trains['data']:\n",
    "                if sum(train['congestionCar']) == 0:\n",
    "                    count += 1\n",
    "            if count == 0:\n",
    "                using_data.append(trains)\n",
    "\n",
    "        df_main = pd.DataFrame(using_data)\n",
    "        df_main['subwayLine'] =res_dict['contents']['subwayLine']\n",
    "        df_main['stationName'] =res_dict['contents']['stationName']\n",
    "        results.append(df_main)\n",
    "df_2=pd.concat(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['time'] = df_1['data'].apply(lambda x: f\"{x[0]['dow']}_{x[0]['hh']}\")\n",
    "\n",
    "total_df = list()\n",
    "for line in [0,1]:\n",
    "    for date in df_1['time'].unique():\n",
    "        cc_df=df_1[(df_1['updnLine']==line) & (df_1['time']==date)]\n",
    "        tmp_list = list()\n",
    "        for i in range(len(cc_df)):\n",
    "            tmp_df=pd.DataFrame(cc_df['data'].reset_index(drop=True)[i])\n",
    "            tmp_df['up_down'] = line\n",
    "            tmp_list.append(tmp_df)\n",
    "        total_df.append(pd.concat(tmp_list))    \n",
    "df_1_cleaned=pd.concat(total_df)\n",
    "df_1_cleaned.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_cleaned.to_csv('data/final_data/sinlim_congest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['time']=df_2['data'].apply(lambda x: f\"{x[0]['dow']}_{x[0]['hh']}\")\n",
    "total_df = list()\n",
    "for line in [0,1]:\n",
    "    for date in df_2['time'].unique():\n",
    "        cc_df=df_2[(df_2['updnLine']==line) & (df_2['time']==date)]\n",
    "        tmp_list = list()\n",
    "        for i in range(len(cc_df)):\n",
    "            tmp_df=pd.DataFrame(cc_df['data'].reset_index(drop=True)[i])\n",
    "            tmp_df['up_down'] = line\n",
    "            tmp_list.append(tmp_df)\n",
    "        total_df.append(pd.concat(tmp_list))    \n",
    "df_2_cleaned=pd.concat(total_df)\n",
    "\n",
    "df_2_cleaned.reset_index(drop=True,inplace=True)\n",
    "for i in range(len(df_2_cleaned['congestionCar'][0])):\n",
    "    df_2_cleaned[f'congestion_{i}']=df_2_cleaned['congestionCar'].apply(lambda x: x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_cleaned.to_csv('data/final_data/sinlim_congest_section.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10621530bc52bc3dcaea48e2b7ef028942e35d2e6e9c9234a88fefd069caf90f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
